{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239ebf50",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11918ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a1175",
   "metadata": {},
   "source": [
    "conexión al servidor MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8400d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Version: 1.25.1\n",
      "Tracking URI: http://ibnodo3:25319\n",
      "Nombre del experimento: regresion-pyspark\n",
      "ID del experimento: 1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Conectandose a MLFlow colocar el nombre asignado por mlflow\n",
    "mlflow.set_tracking_uri(\"http://ibnodo3:25319\")\n",
    "\n",
    "# Generando el experimento o cargandolo si existe\n",
    "experiment_name = \"regresion-pyspark\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Cargando la información\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Vamos a ver si es cierto\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "print(f\"Tracking URI: {mlflow.tracking.get_tracking_uri()}\")\n",
    "print(f\"Nombre del experimento: {experiment_name}\")\n",
    "print(f\"ID del experimento: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a9abf",
   "metadata": {},
   "source": [
    "Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f029eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/17 23:36:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/17 23:36:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/17 23:36:14 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation work completed.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config('spark.sql.debug.maxToStringFields', 2000) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "dataset = spark.read.parquet('/LUSTRE/home/mcd-01/dataset.parquet')\n",
    "dataset = dataset.drop('TOPOSLPX', 'TOPOSLPY', 'SEAICE', 'UOCE', 'VOCE', 'FRC_URB2D', 'SR', 'PCB', 'PC', 'CANWAT')\n",
    "\n",
    "label_column = \"TEMP\"\n",
    "stages = []\n",
    "\n",
    "# Preparing the independent variables (Features)\n",
    "# Defining the variables to be used\n",
    "x_df = dataset.drop('TEMP')\n",
    "variables = x_df.columns\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "va_df = vectorAssembler.transform(dataset)\n",
    "feature_vector = va_df.select('features', 'TEMP')\n",
    "\n",
    "# Initialize the `standardScaler`\n",
    "scaler = StandardScaler(inputCol = 'features',\n",
    "                        outputCol = 'scaledFeatures',\n",
    "                        withMean = True, withStd = True\n",
    "                        ).fit(feature_vector)\n",
    "\n",
    "preppedDataDF = scaler.transform(feature_vector)\n",
    "\n",
    "# Split the featurized training data for training and validating the model\n",
    "(train_data, test_data) = preppedDataDF.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "print('Data preparation work completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bcde3",
   "metadata": {},
   "source": [
    "Gráfica de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274380b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created regression quality plot function\n"
     ]
    }
   ],
   "source": [
    "def plot_regression_quality(predictions):\n",
    "  p_df = predictions.select([\"TEMP\",  \"PRED_TEMP\"]).toPandas()\n",
    "  true_value = p_df.TEMP\n",
    "  predicted_value = p_df.PRED_TEMP\n",
    "\n",
    "  fig = plt.figure(figsize=(15,15))\n",
    "  plt.scatter(true_value, predicted_value, c='crimson')\n",
    " \n",
    "  p1 = max(max(predicted_value), max(true_value))\n",
    "  p2 = min(min(predicted_value), min(true_value))\n",
    "  plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "  plt.xlabel('True Values', fontsize=15)\n",
    "  plt.ylabel('Predictions', fontsize=15)\n",
    "  plt.axis('equal')\n",
    "  \n",
    "  global image\n",
    "\n",
    "  image = fig\n",
    "  fig.savefig(\"LinearRegressionPrediction.png\")\n",
    "  plt.close(fig)\n",
    "  return image\n",
    "\n",
    "print('Created regression quality plot function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b31f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training and evaluation method\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_linear_regression(train_data, test_data, label_column, features_column, elastic_net_param,\n",
    "                            reg_param, max_iter, model_name = None):\n",
    "  # Evaluate metrics\n",
    "  def eval_metrics(predictions):\n",
    "      evaluator = RegressionEvaluator(\n",
    "          labelCol=label_column, predictionCol=\"PRED_TEMP\", metricName=\"rmse\")\n",
    "      rmse = evaluator.evaluate(predictions)\n",
    "      evaluator = RegressionEvaluator(\n",
    "          labelCol=label_column, predictionCol=\"PRED_TEMP\", metricName=\"mae\")\n",
    "      mae = evaluator.evaluate(predictions)\n",
    "      evaluator = RegressionEvaluator(\n",
    "          labelCol=label_column, predictionCol=\"PRED_TEMP\", metricName=\"r2\")\n",
    "      r2 = evaluator.evaluate(predictions)\n",
    "      return rmse, mae, r2\n",
    "\n",
    "  # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "  with mlflow.start_run():\n",
    "    lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"TEMP\", predictionCol='PRED_TEMP')\n",
    "    lrModel = lr.fit(train_data)\n",
    "    predictions = lrModel.transform(test_data)\n",
    "    (rmse, mae, r2) = eval_metrics(predictions)\n",
    "\n",
    "    # Print out model metrics\n",
    "    print(\"Linear regression model (elasticNetParam=%f, regParam=%f, maxIter=%f):\" % (elastic_net_param,\n",
    "                                                                                      reg_param, max_iter))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Log hyperparameters for mlflow UI\n",
    "    mlflow.log_param(\"elastic_net_param\", elastic_net_param)\n",
    "    mlflow.log_param(\"reg_param\", reg_param)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    # Log evaluation metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    # Log the model itself\n",
    "    if model_name is None:\n",
    "      mlflow.spark.log_model(lrModel, \"model\")\n",
    "    else:\n",
    "      mlflow.spark.log_model(lrModel, artifact_path=\"model\", registered_model_name=model_name)\n",
    "    modelpath = \"/LUSTRE/home/mcd-01/artifucks_regresion/model-%f-%f-%f\" % (elastic_net_param, reg_param, max_iter)\n",
    "    mlflow.spark.save_model(lrModel, modelpath)\n",
    "    \n",
    "    # Generate a plot\n",
    "    image = plot_regression_quality(predictions)\n",
    "    \n",
    "    # Log artifacts (in this case, the regression quality image)\n",
    "    mlflow.log_artifact(\"LinearRegressionPrediction.png\")\n",
    "\n",
    "print('Created training and evaluation method')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f16db",
   "metadata": {},
   "source": [
    "se ejecuta el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4835af98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/17 23:39:26 WARN Instrumentation: [32baf784] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/05/17 23:39:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/05/17 23:39:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/05/17 23:39:28 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "22/05/17 23:39:28 WARN Instrumentation: [32baf784] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model (elasticNetParam=0.700000, regParam=0.100000, maxIter=100.000000):\n",
      "  RMSE: 0.29032002404570356\n",
      "  MAE: 0.25066571508317476\n",
      "  R2: 0.9989015750582972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 24:====>                                                   (1 + 12) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_linear_regression(train_data, test_data, label_column='TEMP', features_column= 'scaledFeatures', \n",
    "                        elastic_net_param=0.7, reg_param=0.1, max_iter=100, model_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7899a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
