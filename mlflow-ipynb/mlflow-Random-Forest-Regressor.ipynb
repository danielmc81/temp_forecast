{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239ebf50",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11918ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24199ba7",
   "metadata": {},
   "source": [
    "conexión al servidor MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e8400d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/17 22:41:49 INFO mlflow.tracking.fluent: Experiment with name 'RFregressor-pyspark' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Version: 1.25.1\n",
      "Tracking URI: http://ibnodo3:25319\n",
      "Nombre del experimento: RFregressor-pyspark\n",
      "ID del experimento: 3\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Conectandose a MLFlow colocar el nombre asignado por mlflow\n",
    "mlflow.set_tracking_uri(\"http://ibnodo3:25319\")\n",
    "\n",
    "# Generando el experimento o cargandolo si existe\n",
    "experiment_name = \"RFregressor-pyspark\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Cargando la información\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Vamos a ver si es cierto\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "print(f\"Tracking URI: {mlflow.tracking.get_tracking_uri()}\")\n",
    "print(f\"Nombre del experimento: {experiment_name}\")\n",
    "print(f\"ID del experimento: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a6259",
   "metadata": {},
   "source": [
    "Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88f029eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4087:====>                                                 (1 + 12) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation work completed.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config('spark.sql.debug.maxToStringFields', 2000) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "dataset = spark.read.parquet('/LUSTRE/home/mcd-01/dataset.parquet')\n",
    "dataset = dataset.drop('TOPOSLPX', 'TOPOSLPY', 'SEAICE', 'UOCE', 'VOCE', 'FRC_URB2D', 'SR', 'PCB', 'PC', 'CANWAT')\n",
    "\n",
    "label_column = \"TEMP\"\n",
    "stages = []\n",
    "\n",
    "# Preparing the independent variables (Features)\n",
    "# Defining the variables to be used\n",
    "x_df = dataset.drop('TEMP')\n",
    "variables = x_df.columns\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "va_df = vectorAssembler.transform(dataset)\n",
    "feature_vector = va_df.select('features', 'TEMP')\n",
    "\n",
    "# Initialize the `standardScaler`\n",
    "scaler = StandardScaler(inputCol = 'features',\n",
    "                        outputCol = 'scaledFeatures',\n",
    "                        withMean = True, withStd = True\n",
    "                        ).fit(feature_vector)\n",
    "\n",
    "preppedDataDF = scaler.transform(feature_vector)\n",
    "\n",
    "# Split the featurized training data for training and validating the model\n",
    "(train_data, test_data) = preppedDataDF.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "print('Data preparation work completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4abb9",
   "metadata": {},
   "source": [
    "Gráfica de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "274380b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created regression quality plot function\n"
     ]
    }
   ],
   "source": [
    "def plot_regression_quality(predictions):\n",
    "  p_df = predictions.select([\"TEMP\",  \"prediction\"]).toPandas()\n",
    "  true_value = p_df.TEMP\n",
    "  predicted_value = p_df.prediction\n",
    "\n",
    "  fig = plt.figure(figsize=(15,15))\n",
    "  plt.scatter(true_value, predicted_value, c='crimson')\n",
    " \n",
    "  p1 = max(max(predicted_value), max(true_value))\n",
    "  p2 = min(min(predicted_value), min(true_value))\n",
    "  plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "  plt.xlabel('True Values', fontsize=15)\n",
    "  plt.ylabel('Predictions', fontsize=15)\n",
    "  plt.axis('equal')\n",
    "  \n",
    "  global image\n",
    "\n",
    "  image = fig\n",
    "  fig.savefig(\"RFregressorPrediction.png\")\n",
    "  plt.close(fig)\n",
    "  return image\n",
    "\n",
    "print('Created regression quality plot function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1b31f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training and evaluation method\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def RF_regressor(train_data, test_data, label_column, features_column, maxDepth,\n",
    "                            numTrees, model_name = None):\n",
    "  # Evaluate metrics\n",
    "  def eval_metrics(predictions):\n",
    "      evaluator = RegressionEvaluator(\n",
    "          labelCol=label_column, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "      rmse = evaluator.evaluate(predictions)\n",
    "      evaluator = RegressionEvaluator(\n",
    "          labelCol=label_column, predictionCol=\"prediction\", metricName=\"mae\")\n",
    "      mae = evaluator.evaluate(predictions)\n",
    "      evaluator = RegressionEvaluator(\n",
    "          labelCol=label_column, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "      r2 = evaluator.evaluate(predictions)\n",
    "      return rmse, mae, r2\n",
    "\n",
    "  # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
    "  with mlflow.start_run():   \n",
    "    rfr = RandomForestRegressor(featuresCol = \"scaledFeatures\", labelCol = \"TEMP\")\n",
    "    rfr_model = rfr.fit(train_data)\n",
    "    predictions = rfr_model.transform(test_data)\n",
    "    \n",
    "    (rmse, mae, r2) = eval_metrics(predictions)\n",
    "\n",
    "    # Print out model metrics\n",
    "    print(\"RF regressor model (maxDepth=%f, numTrees=%f):\" % (maxDepth, numTrees))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Log hyperparameters for mlflow UI\n",
    "    mlflow.log_param(\"maxDepth\", maxDepth)\n",
    "    mlflow.log_param(\"numTrees\", numTrees)\n",
    "    # Log evaluation metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    # Log the model itself\n",
    "    if model_name is None:\n",
    "      mlflow.spark.log_model(rfr_model, \"model\")\n",
    "    else:\n",
    "      mlflow.spark.log_model(gbm_model, artifact_path=\"model\", registered_model_name=model_name)\n",
    "    modelpath = \"/LUSTRE/home/mcd-01/artifucks_regresion/model-%f-%f\" % (maxDepth, numTrees)\n",
    "    mlflow.spark.save_model(rfr_model, modelpath)\n",
    "    \n",
    "    # Generate a plot\n",
    "    image = plot_regression_quality(predictions)\n",
    "    \n",
    "    # Log artifacts (in this case, the regression quality image)\n",
    "    mlflow.log_artifact(\"RFregressorPrediction.png\")\n",
    "\n",
    "print('Created training and evaluation method')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a48a36",
   "metadata": {},
   "source": [
    "se ejecuta el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4835af98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF regressor model (maxDepth=15.000000, numTrees=8.000000):\n",
      "  RMSE: 0.6803422511687448\n",
      "  MAE: 0.44071196248894196\n",
      "  R2: 0.9939678617175822\n"
     ]
    }
   ],
   "source": [
    "RF_regressor(train_data, test_data, label_column='TEMP', features_column= 'scaledFeatures', \n",
    "                        maxDepth=15, numTrees=8, model_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7588e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
